# Round 4 Reflection: Final Project Decision

**Name**: Jevin Ta  
**PennKey**: jevinta  
**Date**: November 6, 2025  

---

## 1. What I Explored Today

| Project Name | Source | Key Takeaway (1 sentence) |
|--------------|--------|---------------------------|
| TripTuner | Round 3 / Own Idea | Crowdsourced travel itinerary platform that ranked user submissions using community feedback; strong engagement and clear MVP scope. |
| CrowdBudget | Round 3 Alternative Idea | Budget optimization had potential but required complex financial data and offered less intrinsic motivation for crowd workers. |
| WanderShare | New Instructor Example | Similar in spirit but relied on personalized recommendations rather than collaborative aggregation, making it less testable for Week 1. |

**Resources I used**:
- [x] Rubric scoring (RUBRIC-PROJECT-VIABILITY.md)  
- [x] V2 detailed analyses (reports/v2-analyses/)  
- [x] Steelman Analysis pathways (STEELMAN-ANALYSIS.md)  
- [x] Group discussions  
- [ ] Other  

---

## 2. My Decision

**Project Name**: **TripTuner**

**Decision type**:
- [ ] STAYING with Round 3 project (same approach)  
- [x] STAYING with Round 3 project (modified approach/scope)  
- [ ] PIVOTING to different project  
- [ ] JOINING another team's project  

**If pivoting or adopting someone's idea**:  
N/A  

---

## 3. Why This Decision

**High-level reasoning (2–3 paragraphs):**

TripTuner consistently scored high on feasibility and motivation. The idea solves a relatable pain point — trip planning — using the crowd’s creativity instead of algorithmic recommendations. Earlier rounds showed that participants are excited to share travel experiences for free, making intrinsic motivation and data quality stronger than typical paid tasks.  

I’m refining, not pivoting: Round 4 focuses on narrowing scope to 3–5 pilot destinations, improving the aggregation algorithm, and simplifying the validation test. By emphasizing realistic, student-friendly itineraries and gamified feedback, the project becomes achievable within the semester while maintaining strong originality and engagement potential.  

Key trade-offs included deciding between open-ended creativity (fun but noisy) versus structured submissions (cleaner but restrictive). The current form strikes a balance with required fields and optional comments to ensure usable data.  

**What convinced me**:
- Clear real-world problem with measurable crowd output  
- High intrinsic motivation for participants  
- Strong scalability and low hosting cost  

**What concerns me (and how I’ll address it):**
- **Low participation early on** → Seed initial itineraries and post calls on Reddit + Penn Slack  
- **Quality variation** → Use AI moderation + minimum completeness rules  

---

## 4. What I'm Building

**One-sentence project description:**  
TripTuner is a crowdsourced travel-planning platform where users collaboratively submit, rate, and refine itineraries to surface the most realistic and well-balanced trip plans.  

**MVP Scope (3–4 core features only):**

1. **Itinerary Submission Form:** Structured entry for destination, budget, duration, and activities.  
2. **Voting & Feedback System:** Crowd scores each itinerary for realism, value, and fun.  
3. **Aggregated Ranking Engine:** Weighted score combining votes, sentiment, and completeness.  
4. **Tag Filtering:** Users browse by theme (budget, foodie, adventure).  

**What I'm explicitly NOT building (to keep scope realistic):**
- No AI-generated itineraries  
- No full booking or maps integration  
- No user accounts or payment systems  

---

## 5. Week 1 Validation

**The specific test I'll run Week 1:**

- **Where:** Reddit (r/travel, r/solotravel) + Penn student discussion forum 
- **When:** Tuesday Nov 11
- **What:** Post a Google Form asking users to submit a short day itinerary for Philly, then vote on others’ submissions.  
- **Success metric:** ≥ 20 unique submissions and ≥ 50 votes within 48 hours; ≥ 70 % positive feedback on usefulness.  

**If Week 1 test fails, I will**:
- [ ] Pivot to: Simplified voting-only version (fixed example itineraries)  
- [ ] Use MTurk / paid participants for validation  
- [x] Try different recruitment channel: Instagram travel accounts  
- [ ] Simplify the task to: 1-sentence activity list instead of full itinerary  

---

## 6. **Tentative** Team (Optional)

**Team members**:
1. Jevin Ta (jevinta) – Project lead / Full-stack dev  
2. Julia Zhuo (juzhuo) – UI design / Frontend  
3. Arushi Agarwal (arushiga) – Crowd validation / Data collection  
4. Liana Veerasamy (lianav) – Project co-lead / full-stack dev 
5. Sadia Rahman (rsadia) – Gamification & testing  

**Team status**:
- [x] Same team from Round 3  
- [ ] New team formed during Round 4  
- [ ] Solo (will find teammates later)  
- [ ] Joining an existing team  

---

## 7. Reflection

**Most valuable part of Round 4:**  
The rubric and steel-man exercises clarified which parts of the project needed simplification for feasibility; peer discussions helped sharpen the MVP scope.  

**Biggest surprise:**  
Realizing how motivated travelers are to contribute voluntarily — intrinsic reward outweighed small monetary incentives.  

**One thing I'd tell future students about Round 4:**  
Focus on running a concrete validation plan early — a small but measurable test tells you more than adding features.  

---

## Commitment

**I commit to**:
- [x] Building the MVP scope above (3–4 features maximum)  
- [x] Running a concrete Week 1 validation test  
- [x] Pivoting if Week 1 shows <20% success  
- [x] Meeting with instructor if I hit major blockers  

**Signature:** Jevin Ta  
**Date:** Nov 6, 2025  

---

## Submission

1. Save as `round4/jevinta.md`  
2. Submit via pull request  
3. Deadline: [Instructor will specify]
